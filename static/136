<?xml version="1.0"?>
<?xml-stylesheet 
 href="http://www.w3.org/2000/08/w3c-synd/style.css" type="text/css"
?>
<rss version="0.91"><channel><title>Planet PHP</title><link>http://planet-php.net</link><description>People blogging about PHP</description><language>en</language><item><title>Doing the Heavy Lifting: Gearman and Magento - TechPortal</title><link>http://techportal.ibuildings.com/2011/01/17/doing-the-heavy-lifting-gearman-and-magento/</link><pubDate>Mon, 17 Jan 2011 09:12:05 +0000</pubDate><description><![CDATA[<p>With most web applications, there comes a time where there is a need to perform either CPU or I/O intensive work based on user actions.  Whether processing uploaded files, or performing system-wide database updates, developers are increasingly turning to <a href="http://www.gearman.org/">Gearman</a> as a simple way to hand off the heavy lifting to another server to be performed asynchronously.  It is easy to install and configure and has interfaces to many popular languages, including PHP.<br/>
With this in mind, the team at <a href="http://ibuildings.com">Ibuildings</a> created a module to allow easy usage of Gearman from within the open source ecommerce solution <a href="http://www.magentocommerce.com/">Magento</a>.  Releasing this module provides a simple way to perform job queue operations within the popular open-source ecommerce platform.  The module is open source and freely available for download at <a href="https://github.com/ibuildings/Magento-Gearman-Module/tree/Version_1_0_0">https://github.com/ibuildings/Magento-Gearman-Module/tree/Version_1_0_0</a>.  This tutorial walks through installation of the module and some examples using it; it is assumed that you are already familiar with Magento development to begin this tutorial.<br/><span id="more-2902"/></p>
<h3>Preparation</h3>
<p>Once you have a working installation of Magento, you will need to install Gearman and the PHP classes to work with it.  Here are some example steps, aimed at a Debian-based system for illustration purposes.<br/><code>
<pre>$ sudo apt-get install libgearman-dev
$ sudo pecl install gearman
</pre>
<p/></code><br/>
While developing, you might wish to run the Gearman worker also on your development environment or virtual machine.  If so, then you will need to install the server packages for Gearman as well:<br/><code>
<pre>$ sudo apt-get install gearman-job-server</pre>
<p/></code><br/>
At this point you can install the Ibuildings_Gearman module into your Magento installation.  Change into the {MAGENTO_ROOT}/app directory and install the module directly from <a href="http://github.com">GitHub</a> with the following command:<br/><code>
<pre>$ git git://github.com/frak/Magento-Gearman-Module.git</pre>
<p/></code><br/>
Once you have cleared your cache, you should then go to the <strong>System > Configuration</strong> page, and look for the “Ibuildings Gearman Module” configuration section.  Here you will need to add the IP address and port for your Gearman server.  If you are running on a development machine with a local Gearman job server, the settings will be “127.0.0.1″ and “4730″ respectively.</p>
<h3>Implementation</h3>
<p>There were two scenarios that were envisaged when developing this component: a situation where you would “fire and forget” the job, where you can safely ignore the status of the job during its lifecycle, or where you would like a reference to the job so that you can check its status periodically and update the user as to job progress.<br/>
For the first situation, the module employs the Magento Event/Observer pattern, and can be used from a Model object as follows:<br/><code/></p>

<div class="wp_syntax"><div class="code"><pre class="php" style="font-family:monospace;"><span style="color: #000088;">$event</span> <span style="color: #339933;">=</span> <span style="color: #990000;">array</span><span style="color: #009900;">(</span><span style="color: #009900;">)</span><span style="color: #339933;">;</span>
<span style="color: #000088;">$event</span><span style="color: #009900;">[</span><span style="color: #0000ff;">'queue'</span><span style="color: #009900;">]</span> <span style="color: #339933;">=</span> <span style="color: #0000ff;">'test'</span><span style="color: #339933;">;</span>
<span style="color: #000088;">$event</span><span style="color: #009900;">[</span><span style="color: #0000ff;">'task'</span><span style="color: #009900;">]</span>  <span style="color: #339933;">=</span> <span style="color: #990000;">array</span><span style="color: #009900;">(</span>
    <span style="color: #0000ff;">'id'</span>       <span style="color: #339933;">=></span> <span style="color: #cc66cc;">1234</span><span style="color: #339933;">,</span>
    <span style="color: #0000ff;">'data'</span>     <span style="color: #339933;">=></span> <span style="color: #0000ff;">'This is a string!'</span><span style="color: #339933;">,</span>
    <span style="color: #0000ff;">'callback'</span> <span style="color: #339933;">=></span> <span style="color: #0000ff;">'http://some.example.com/work_was_done.php'</span>
<span style="color: #009900;">)</span><span style="color: #339933;">;</span>
Mage<span style="color: #339933;">::</span><span style="color: #004000;">dispatchEvent</span><span style="color: #009900;">(</span><span style="color: #0000ff;">'gearman_do_async_task'</span><span style="color: #339933;">,</span> <span styl=""/></pre></div></div><p><i>Truncated by Planet PHP, read more at <a href="http://techportal.ibuildings.com/2011/01/17/doing-the-heavy-lifting-gearman-and-magento/">the original</a> (another 17642 bytes)</i></p>]]></description></item><item><title>Habari plugins published - Michael Maclean</title><link>http://mgdm.net/weblog/habari-plugins-published</link><pubDate>Sun, 16 Jan 2011 22:54:32 +0000</pubDate><description><![CDATA[<p>I've just committed two new plugins to the habari-extras Subversion. Firstly, there's the 'share' plugin, which adds the Facebook OpenGraph metadata to pages so that the Like button works, and also adds Facebook and Twitter widgets to the bottom of posts. Secondly, there's a bitly plugin, that pings bit.ly's API when every post is published and generates a short URL. This URL is then stored in the post info, and it provides a template to add it to the head of each page using the <a href="http://microformats.org/wiki/rel-shortlink">shortlink</a> markup. I'd be interested in feedback from anyone more familar with Habari in case there's a better way to do what I'm doing.</p><ul><li><a href="http://svn.habariproject.org/habari-extras/plugins/share/">Share plugin</a></li><li><a href="http://svn.habariproject.org/habari-extras/plugins/bitly/">Bit.ly plugin</a></li></ul>]]></description></item><item><title>Pdf Presenter Console 2.0 released - Jakob Westhoff</title><link>http://westhoffswelt.de/blog/0058_pdf_presenter_console_version_2.0_released.html</link><pubDate>Sun, 16 Jan 2011 16:12:00 +0000</pubDate><description><![CDATA[I am very happy to announce that I finally had some time to release version 2.0 of my PDF-Presenter-Console. It is filled with new features like navigational link support and cache compression, as well as many bug fixes. Go get it while it's hot!
]]></description></item><item><title>Recent activity: Habari plugins - Michael Maclean</title><link>http://mgdm.net/weblog/recent-activity-habari-plugins</link><pubDate>Sat, 15 Jan 2011 22:54:04 +0000</pubDate><description><![CDATA[<p>I think I'm just about keeping to this one-post-a-week thing, almost. I've recently been playing with the internals of Habari, writing a couple of plugins. I've found it quite well put together, though I don't seem to ever get the Utils::debug() output to display properly - though this might have been due to the code I was writing running before a redirect. I believe though that I now have got 2 plugins which I'm going to investigate publishing - one which generates the Facebook and Twitter widgets at the bottom of the posts (and the relevant OpenGraph metadata for Facebook in the header), and another which pings bit.ly and generates a short URL for each post as it's published. I'm writing this post in part as a test to see that it works for real :-)</p><p>If I get a bit of time over the next few days, I'll finish tidying them up and make them available. If anyone's interested before I do, drop me an email or catch me on Twitter.</p>]]></description></item><item><title>2011, PHP Advent and First-Class APIs - Helgi &#xDE;ormar &#xDE;orbj&#xF6;rnsson</title><link>http://helgi.ws/2011/01/15/php-advent-and-first-class-apis/</link><pubDate>Sat, 15 Jan 2011 16:54:18 +0000</pubDate><description><![CDATA[<p>And here we are, 2011, excitement in the air and all that jazz! It’s looking to be a great year ahead of myself and my company (<a title="echolibre" href="http://www.echolibre.com">echolibre</a>). I’ll be speaking at a few conferences this year such as <a title="Tek 11" href="http://tek11.phparch.com">PHP Tek</a> and writing articles for various magazines and online publications – I already have 2 slated for PHP Architect and as a bonus I will be publishing my old PHP Architect articles and columns to this blog in the coming days :-)</p>
<p>On the subject on online publications, last December I wrote an article called <a title="First-Class APIs" href="http://phpadvent.org/2010/first-class-apis-by-helgi-%C3%9Eormar-%C3%9Eorbj%C3%B6rnsson">First-Class APIs</a> for the <a title="PHP Advent" href="http://www.phpadvent.org">PHP Advent Calendar</a> – A topic I enjoyed a lot writing about. But I wanted to take a minute to thank my two good friends <a title="Sean Coates" href="http://seancoates.com/">Sean</a> and <a title="Chris Shiflett" href="http://www.shiflett.org">Chris</a> for taking their personal time to bring the whole thing together. Editing articles, cat herding writers and generally being awesome for helping the PHP community to be even beter. If you have never read any of the articles that get published on PHP Advent then head over there right now and read up on them! I’ve been privileged enough to have an article up there the past 3 years and hope I get to write for them again this year :-)</p>
<p>Seems they don’t have any way on the website it self to go back years so here you go: <a title="PHP Advent 2010" href="http://phpadvent.org/2010">2010</a> – <a title="2009" href="http://phpadvent.org/2009">2009</a> – <a title="PHP Advent 2008" href="http://phpadvent.org/2008">2008</a></p>
<p>Anyway, I just wanted to get my blog rolling for 2011 and here’s hoping I can keep up a real blogging schedule at least for the first part of the year! :-)</p>
<br />Filed under: <a href='http://helgi.ws/category/php/'>PHP</a>  <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gocomments/helgithormar.wordpress.com/157/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/helgithormar.wordpress.com/157/" /></a> <a rel="nofollow" href="http://feeds.wordpress.com/1.0/godelicious/helgithormar.wordpress.com/157/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/delicious/helgithormar.wordpress.com/157/" /></a> <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gofacebook/helgithormar.wordpress.com/157/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/facebook/helgithormar.wordpress.com/157/" /></a> <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gotwitter/helgithormar.wordpress.com/157/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/twitter/helgithormar.wordpress.com/157/" /></a> <a rel="nofollow" href="http://feeds.wordpress.com/1.0/gostumble/helgithormar.wordpress.com/157/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/stumble/helgithormar.wordpress.com/157/" /></a> <a rel="nofollow" href="http://feeds.wordpress.com/1.0/godigg/helgithormar.wordpress.com/157/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/digg/helgithormar.wordpress.com/157/" /></a> <a rel="nofollow" href="http://feeds.wordpress.com/1.0/goreddit/helgithormar.wordpress.com/157/"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/reddit/helgithormar.wordpress.com/157/" /></a> <img alt="" border="0" src="http://stats.wordpress.com/b.gif?host=helgi.ws&blog=9635834&post=157&subd=helgithormar&ref=&feed=1" width="1" height="1" />]]></description></item><item><title>Literate programming with PHP - Henri Bergius</title><link>http://bergie.iki.fi/blog/literate_programming_with_php/</link><pubDate>Sat, 15 Jan 2011 15:31:10 +0000</pubDate><description><![CDATA[
<p><code>noweb.php</code> is a PHP implementation of the tool needed for <a href="http://en.wikipedia.org/wiki/Literate_programming">literate programming</a>. Wikipedia says the following about literate programming:</p>

<blockquote>
  <p>The literate programming paradigm, as conceived by Knuth, represents a move away from writing programs in the manner and order imposed by the computer, and instead enables programmers to develop programs in the order demanded by the logic and flow of their thoughts. Literate programs are written as an uninterrupted exposition of logic in an ordinary human language, much like the text of an essay, in which macros which hide abstractions and traditional source code are included. Literate programming tools are used to obtain two representations from a literate source file: one suitable for further compilation or execution by a computer, the "tangled" code, and another for viewing as formatted documentation, which is said to be "woven" from the literate source. While the first generation of literate programming tools were computer language-specific, the later ones are language-agnostic and exist above the programming languages.</p>
</blockquote>

<p><code>noweb.php</code> is able to facilitate this model of working by being able to extract program code from textual documents describing how the program ought to work. This document itself is such a description, and <code>noweb.php</code> PHP code can be generated from it.</p>

<p>The inspiration for creating <code>noweb.php</code> comes from Jonathan Aquino's work on implementing the same with Python. See his <a href="http://jonaquino.blogspot.com/2010/04/nowebpy-or-worlds-first-executable-blog.html">world's first executable blog post</a> and the actual <a href="https://github.com/JonathanAquino/noweb.py">noweb.py project on GitHub</a>.</p>

<h2>Download</h2>

<p>If you're interested in doing literate programming with PHP, grab the software produced by this document from GitHub:</p>

<p><a href="https://github.com/bergie/noweb.php">https://github.com/bergie/noweb.php</a></p>

<p><code>noweb.php</code> requires PHP 5.3 or newer.</p>

<h2>Usage</h2>

<p><code>noweb.php</code> is a PHP tool that reads a text file with <a href="http://en.wikipedia.org/wiki/Noweb#Noweb.27s_input">noweb-style</a> annotated software code macros in it, parses it and writes the files defined in the document into the file system.</p>

<pre><code>$ noweb.php tangle README.txt
</code></pre>

<p>The resulting code files will be written into the same directory where the document resides.</p>

<p>If you just want to see what code files the document defines, you can also run:</p>

<pre><code>$ noweb.php list README.txt
</code></pre>

<h2>Getting a file</h2>

<p>When <code>noweb.php</code> starts, we check for the command line arguments to get a file. If no argument is found, we abort and give users instructions:</p>

<pre title="getting the file">
if (basename($_SERVER['argv'][0]) == 'php')
{
    // The script was run via $ php noweb.php, tune arguments
    array_shift($_SERVER['argv']);
}
if (count($_SERVER['argv']) != 3)
{
    die("Usage: noweb.php tangle &lt;textfile>\n");
}
</pre>

<p>We get the command and filename from the arguments:</p>

<pre title="getting the file">
$command = $_SERVER['argv'][1];
$readfile = $_SERVER['argv'][2];
</pre>

<p>The we check that the given file actually exists:</p>

<pre title="getting the file">
if (!file_exists($readfile))
{
    die("File {$readfile} not found\n");
}
</pre>

<p>And then we parse the file for any literate programming code, and extract the code. The workings of this is explained in detail later.</p>

<pre title="getting the file">
$noweb = new noweb();
$noweb->read_chunks($readfile);
</pre>

<p>We check the command given by the user and perform it:</p>

<pre title="running the command">
switch ($command)
{
    case 'list':
        $noweb->list_files();
        break;
    case 'tangle':
        $noweb->tangle_files(dirname($readfile));
        break;
    case 'weave':
        $noweb->weave($readfile);
        break;
    default:
        die("Unknown command {$command}. Try 'tangle'\n");
}
</pre>

<h2>Reading the file</h2>

<p>In a literate program the actual software code is stored in chunks inside the document. A chunk is defined by a name inside <code>&lt;&lt;</code> and <code>>>=</code>, and it ends on a line containing just <code>@</code>.</p>

<p>For parsing the chunks we will need two regular expressions:</p>

<pre title="chunk regular expressions">
private $chunk_start_regexp = '/^&lt;&lt;([^>]+)>>=/';
private $chunk_end_regexp = '/^@$/';
</pre>

<p>When reading a literate programming file, we handle it on line-by-line basis, keeping track of whether we're inside a chunk or documentation:</p>

<pre title="reading the file">
$lines = file($filename);
$chunk = null;
foreach ($lines as $line)
{
    &lt;&lt;reading line of the file>>
}
</pre>

<p>With each line of the </p><p><i>Truncated by Planet PHP, read more at <a href="http://bergie.iki.fi/blog/literate_programming_with_php/">the original</a> (another 7732 bytes)</i></p>]]></description></item><item><title>A Year Of Zend Framework Bug-Hunt In Review - Zend Developer Zone</title><link>http://devzone.zend.com/article/12942-A-Year-Of-Zend-Framework-Bug-Hunt-In-Review</link><pubDate>Fri, 14 Jan 2011 15:03:30 +0000</pubDate><description><![CDATA[
                 2010 closed out on a pretty good note for the  Zend Framework  developer community.  The december bug-hunt closed out with a solid  37 issues (as of Jan. 12, 2011) .  This bug-hunt was led by Ramon Ornelas in first place with 11 issues and Thomas Weidner trailing one issue behind with 10 issues resolved.  11 unique developers joined in to help make this bug-hunt a success.  To Ramon, Thomas and the 9 other developers: the Zend Framework team cannot thank you enough for taking part and giving back to this project.  It is contributions like these that make the Zend Framework the high-quality and widely popular PHP framework that it is.
            ]]></description></item><item><title>Technical New Year&#x2019;s Resolutions: 2011 - Brian DeShong</title><link>http://www.deshong.net/2011/01/technical-new-years-resolutions-2011/</link><pubDate>Fri, 14 Jan 2011 03:39:03 +0000</pubDate><description><![CDATA[<p>
Better late than never, right?  I should’ve done this in December, but at least it’s only two weeks into the New Year.
</p>
<p>
Last year was a great year.  Looking back at my 2010 resolutions, here’s what I accomplished:</p>
<ul>
<li>Learn a new language — really dove head first into learning Objective-C, along with the Cocoa and UIKit frameworks</li>
<li>Built and released my first iOS app, <a href="http://floodwatchapp.com/">FloodWatch</a></li>
</ul>
<p>
My <a href="/2009/12/technical-new-years-resolutions-2010/">2010 resolutions</a> aside, I also managed to <a href="/2010/03/goodbye-schematic-hello-yahoo">make a move to Yahoo!</a>, start to hone my front end developer skills, do some Java work, learn some <a href="http://hadoop.apache.org/">Hadoop</a> and <a href="http://pig.apache.org/">Pig</a> scripting, learn some <a href="http://lua.org/">Lua</a>, and <a href="/2010/10/barcamp-charleston-2010/">speak at BarCamp Charleston</a>.  It’s been a busy year!
</p>
<p>
I’ve been absolutely horrible at blogging over the past year, though.  Two posts in 2010 is just pitiful and sad.  Shame on me.
</p>
<p>
So, given the look back and the year ahead, here’s what I’m challenging myself with:</p>
<ul>
<li><b>Blog more:</b> This is the biggest resolution of them all. I really need to write a few blog posts a month on whatever it is that I’m working on, when I might have something that can and should be shared with a larger potential audience.  More often than not, I complete my tasks at hand and charge ahead to the next ones.  I need to take more time to stop, reflect, and share.</li>
<li><b>Speak at more user groups and conferences:</b> …this is already in the works, too, with my first 2011 talk at <a href="http://atlantaphp.org/">Atlanta PHP</a> on February 3, 2011. I’ll be talking on the <a href="http://developer.yahoo.com/yql/">Yahoo! Query Language</a>.</li>
<li><b>Write another article:</b> …already in the works!  Look for it later in the year.</li>
<li><b>Continue to sharpen my development and architecture skills:</b> I’ve learned an amazing amount of new things during my time at Yahoo!  I work with some ridiculously smart people, and am constantly learning from them and becoming a better developer because the people in my environment.  I’m loving every single day in the office where I get to focus on code and architecture.  This one should be a breeze.</li>
<li><b>Read some of the classic programming books again:</b> Classic books like <a href="http://www.pragprog.com/the-pragmatic-programmer">The Pragmatic Programmer</a> and <a href="http://cc2e.com/">Code Complete</a> are great to read every few years to keep yourself grounded and humble.  This should be one of those years for me.</li>
<li><b>Build another app of some sort, iOS, Mac or otherwise:</b> …have some ideas here, should be totally doable.</li>
<li><b>Spend some more time with PHP:</b> I haven’t written much PHP since mid-2010, so it’d be nice to get back to it.  I should contribute to Zend Framework, etc. — that’d be a great way to achieve this goal, while contributing to the community at the same time.</li>
<li><b>Get back on the conference circuit:</b> I didn’t do so well with this in 2010, mostly due to my job change.  I’d like to get to at least one PHP, OSS, or development conference in 2011.</b></li>
</ul>
<p>
So, that’s what I’ll be doing in 2011.  Hopefully I’ll be here about 50 weeks from now, recounting how I knocked out every single one of these.
</p>
<p>
What are <em>you</em> doing in 2011?</p>
]]></description></item><item><title>Google and H.264 &#x2013; Far From Hypocritical? - Marco Tabini</title><link>http://blogs.computerworlduk.com/simon-says/2011/01/google-and-h264---far-from-hypocritical/index.htm?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=google-and-h-264-far-from-hypocritical</link><pubDate>Thu, 13 Jan 2011 17:33:28 +0000</pubDate><description><![CDATA[<p>Simon Phipps, on the <a href="http://www.engadget.com/2011/01/11/google-will-drop-h-264-support-from-chrome-herd-the-masses-towa/">Google dropping H.264 from Chrome</a> debacle:</p>
<blockquote><p>But all these points are also true of Adobe Flash. So why not drop that too? Is it not hyprocritical to keep it? If you’re an absolutist, probably yes. But there’s a calculation going on here about steering the web into the level plains of truly open standards. H.264 support in the &lt;video> tag is not the same as Flash support.</p></blockquote>
<p>Simon (whom I greatly respect) makes some great points in his essay—primarily outlining the fact that an <em>honest</em> analysis<sup class='footnote'><a href='#fn-949-1' id='fnref-949-1'>1</a></sup> of what has happened needs to take a lot of complex and interrelated events into account.</p>
<p>I do think, however, that his conclusion is incorrect in this particular instance. Google is not a disinterested party in the video format war; it controls the WebM codec <em>de facto</em>, because it originates the format and because several of the big-name members of the WebM consortium derive large portions of their income from it<sup class='footnote'><a href='#fn-949-2' id='fnref-949-2'>2</a></sup>. It also controls YouTube, which is arguably the largest repository of videos on the Web.</p>
<p>Flash seems more like a red herring to me—the real question is, <em>where are the disclosures?</em> This action and the naïve reasoning that Google has presented gives no consideration to what a company whose motto is “do no evil” apparently stands to gain from this move, which could be something as simple as not wanting to worry about having to pay for royalties five or ten years down the road<sup class='footnote'><a href='#fn-949-3' id='fnref-949-3'>3</a></sup>.</p>
<p>What worries me and what I’d think should have worried Simon is the fact that this move <em>reduces</em> customer choice, which goes against the very principles of openness that Google claims to support. Given the current situation, under which they can continue to use H.264 without any significant cost, the appropriate choice would be to leave the codec in and let the market decide. If the open-source model yields a better result in the long run, as I believe it does, then there is nothing to fear.
<div class='footnotes'>
<div class='footnotedivider'></div>
<ol>
<li id='fn-949-1'>Something that requires <a href="http://twitter.com/#!/mtabini/status/24937389625442304">more than 140 characters</a>, that is. <span class='footnotereverse'><a href='#fnref-949-1'>↩</a></span></li>
<li id='fn-949-2'>See the latest <a href="http://awurl.com/eSXVAlmj8">Mozilla Foundation report</a>, for example. <span class='footnotereverse'><a href='#fnref-949-2'>↩</a></span></li>
<li id='fn-949-3'>Should the royalty scheme of H.264 ever change in a way that affects Google and YouTube, both would thus be in the clear, and everybody else would conceivably be covered by Flash or its successors. <span class='footnotereverse'><a href='#fnref-949-3'>↩</a></span></li>
</ol>
</div>
]]></description></item><item><title>Why a project switched from Google Search Appliance to Zend_Lucene - Liip </title><link>http://blog.liip.ch/archive/2011/01/13/why-a-project-switched-from-google-search-appliance-to-zend_lucene.html</link><pubDate>Thu, 13 Jan 2011 14:20:56 +0000</pubDate><description><![CDATA[<p>Google technology does a good job when searching the wild and treacherous realms of the public internet. However, the commercial Google Search Appliance (GSA) sold for searching intranet websites did not convince me at all. For a client, we first had to integrate the GSA, later we reimplemented search with Zend_Lucene. Some thoughts comparing the two search solutions.</p>
<p>This post became rather lengthy. If you just want the summary of my pro and con for GSA versus Lucene, scroll right to the end :-)</p>
<p>In a project we got to take over, the customer had already bought a GSA (the "cheap" one - only about $20'000). There was a list of wishes from the client how to optimally integrate the appliance into his web sites:</p>
<ul><li>Limit access to authorized users</li>
    <li>Index all content in all languages</li>
    <li>Filter content by target group (information present as META in the html headers)</li>
    <li>Show a box with results from their employee directory</li>
</ul><h2>GSA Software</h2>
<p>The GSA made problems with most of those requests.</p>
<p>When you activate <strong>access protection</strong>, the GSA makes a HEAD request on the first 20 or so search results for each single search request, to check if that user has the right to see that document. As on our site, there are no individual visibility requirements, we did not need that. But there is no way to deactivate this check, resulting in unnecessary load on the web server. We ended up catching the GSA HEAD request quite early and just send a Not Modified response without further looking into the request.</p>
<p>The <strong>GSA completely ignores the language declaration</strong> (whether in META or in the  attribute or inside the html head) and uses it's own heuristics. This might be fine for public Internet, when you can assume many sites declaring their content to be in the server installation language even if it is not - but in a controlled environment we can make sure those headers are correct. We talked to google support about this, but they could only confirm that its not possible. This was annoying, as the heuristics was wrong, for example when some part of a page content was in another language.</p>
<p>The spider component messed up with some bugs from the web site we needed to index. We found that the same parameter got repeated over and over on an URL. Those cycles led to having the same page indexed many times and the limit of 500'000 indexed pages being filled up. This is of course a bug in the web server, but we found no way to help the GSA not to stumble over it.</p>
<p>Filtering by <strong>meta information</strong> would work. But we have binary documents like PDF, Word and so on. There was no way to set the meta information for those documents. <tt>requiredfields=gsahintview:group1|-gsahintview</tt> should trigger a filter to say either we have the meta information with a specific value, or no meta at all. However, Google confirmed that, this combination of filter expressions is not possible. They <a href="http://code.google.com/apis/searchappliance/documentation/50/xml_reference.html#request_meta_filter">updated their documentation</a> to at least explain the restrictions.</p>
<p>The only thing that really worked without hassle was the search box. You can configure the GSA to request data from the web server and return an XML fragment that is integrated into the search result page.</p>
<p>Support by Google was a very positive aspect. They answered fast and without fuss, and have been motivated to help. They seemed competent - so I guess when they did not propose alternatives but simply said there is no such feature, there really was no alternative for our feature requests.</p>
<h2>GSA Hardware</h2>
<p>The google hardware however was a real nuisance. You get the appliance as a standard sized server to put into the rack. Have the hardware locally makes sense. It won't use external bandwith for indexing and you can be more secure about your confidential data. But during the 2 years we used the GSA, there were 3 hardware failures. As part of the setup test, our hoster checks if the system work properly by unplugging the whole system. While this is not good for data of course, the hardware should survive that. The GSA did not and had to be sent for repair. There were two more hardware issues - one was simply a RAM module signaling an error. But as the hoster is not allowed to open the box, even such simple repair took quite a while. Our client did not want to buy more than one Appliance for his system, as they are rather expensive. So you usually do not have a replacement ready. With any other server, the hoster can fix the system rather fast or in the worst case just re-install the system from backups. With the GSA there is no such redundancy.</p>
<p>The GSA is not only closed in on hardware level. You also do not have shell access to the system, so all configuration has to be done in the web interface. Ver</p><p><i>Truncated by Planet PHP, read more at <a href="http://blog.liip.ch/archive/2011/01/13/why-a-project-switched-from-google-search-appliance-to-zend_lucene.html">the original</a> (another 6419 bytes)</i></p>]]></description></item></channel></rss>
